{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c973fcc-0bba-44c3-853c-8b56effc5a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRDS local filepath: /home/fran/crds_cache\n",
      "CRDS file server: https://jwst-crds.stsci.edu\n"
     ]
    }
   ],
   "source": [
    "# Basic import necessary for configuration.\n",
    "import os\n",
    "import warnings\n",
    "import requests\n",
    "\n",
    "warnings.simplefilter(\"ignore\", RuntimeWarning)\n",
    "\n",
    "maindir = os.path.join(os.getcwd(), '../Data/')\n",
    "\n",
    "# Set CRDS cache directory to user home if not already set.\n",
    "if os.getenv('CRDS_PATH') is None:\n",
    "    os.environ['CRDS_PATH'] = os.path.join(os.path.expanduser('~'), 'crds_cache')\n",
    "\n",
    "# Check whether the CRDS server URL has been set. If not, set it.\n",
    "if os.getenv('CRDS_SERVER_URL') is None:\n",
    "    os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'\n",
    "\n",
    "# Output the current CRDS path and server URL in use.\n",
    "print('CRDS local filepath:', os.environ['CRDS_PATH'])\n",
    "print('CRDS file server:', os.environ['CRDS_SERVER_URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5744c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------General Imports----------------------\n",
    "import time\n",
    "import glob\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --------------------Astroquery Imports---------------------\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "# ----------------------Astropy Imports----------------------\n",
    "# Astropy utilities for opening FITS files, downloading demo files, etc.\n",
    "from astropy.table import Table\n",
    "from astropy.stats import sigma_clip\n",
    "from astropy.visualization import ImageNormalize, ManualInterval, LogStretch\n",
    "from astropy.visualization import LinearStretch, AsinhStretch, simple_norm\n",
    "\n",
    "# ----------------------Plotting Imports---------------------\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "# -------------------File Download Imports-------------------\n",
    "from tqdm.auto import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf08781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_change(a, b):\n",
    "    \"\"\" Find the change in the order of magnitude between two values.\"\"\"\n",
    "    return np.abs(np.log10(abs(a)) - np.log10(abs(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5deee1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import binary_fill_holes, binary_erosion\n",
    "from scipy import ndimage\n",
    "\n",
    "def find_closed_shape_contour(pixel_array, closed_shape_pixels):\n",
    "    mask = np.zeros_like(pixel_array, dtype=bool)\n",
    "\n",
    "    for pixel in closed_shape_pixels:\n",
    "        mask[pixel[0], pixel[1]] = 1\n",
    "\n",
    "    rows, cols = pixel_array.shape\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            # Check if the pixel is part of the closed shape\n",
    "            if np.isnan(pixel_array[row, col]):\n",
    "                mask[row, col] = 1\n",
    "\n",
    "    # Expand the mask by setting ones to the expanded pixel array size by one pixel\n",
    "    expanded_mask = np.pad(mask, pad_width=1, mode='constant', constant_values=1)\n",
    "    expanded_mask[1:-1, 1:-1] |= mask\n",
    "    mask = expanded_mask\n",
    "\n",
    "    # Fill patches of 0 surrounded by 1s with 1s, but only if the holes are <= 20 pixels in size\n",
    "    labeled_array, num_features = ndimage.label(~mask)\n",
    "    sizes = ndimage.sum(~mask, labeled_array, range(num_features + 1))\n",
    "    for i, size in enumerate(sizes):\n",
    "        if size <= 20:\n",
    "            mask[labeled_array == i] = 1\n",
    "\n",
    "    # Remove the outer pixels of each shape\n",
    "    mask = binary_erosion(mask)\n",
    "\n",
    "    # remove the edges of the mask\n",
    "    mask = mask[1:-1, 1:-1]\n",
    "\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db465713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dead_pixels(data, threshold=1):\n",
    "    rows, cols = data.shape\n",
    "    dead_pixels, closed_shape_pixels = set(), set()\n",
    "\n",
    "    for row in range(rows - 1):\n",
    "        for column in range(cols - 1):\n",
    "            if np.isnan(data[row, column]):\n",
    "                dead_pixels.add((row, column))\n",
    "\n",
    "                # Check surrounding pixels for extreme jumps around NaN\n",
    "                for dr in [-1, 0, 1]:\n",
    "                    for dc in [-1, 0, 1]:\n",
    "                        if dr == 0 and dc == 0:\n",
    "                            continue\n",
    "                        nr, nc = row + dr, column + dc\n",
    "                        # Only consider non-NaN neighbors\n",
    "                        if 0 <= nr < rows and 0 <= nc < cols and not np.isnan(data[nr, nc]):\n",
    "                            # Compare this neighbor to its own neighboring pixels\n",
    "                            for dr2 in [-1, 0, 1]:\n",
    "                                for dc2 in [-1, 0, 1]:\n",
    "                                    if dr2 == 0 and dc2 == 0:\n",
    "                                        continue\n",
    "                                    r2, c2 = nr + dr2, nc + dc2\n",
    "                                    if 0 <= r2 < rows and 0 <= c2 < cols and not np.isnan(data[r2, c2]):\n",
    "                                        if absolute_change(data[nr, nc], data[r2, c2]) > threshold:\n",
    "                                            # Before marking, ensure all 8 around the NaN are valid (not NaN)\n",
    "                                            neighbors = [(row + adr, column + adc)\n",
    "                                                         for adr in [-1, 0, 1]\n",
    "                                                         for adc in [-1, 0, 1]\n",
    "                                                         if not (adr == 0 and adc == 0)]\n",
    "                                            if all(0 <= rr < rows and 0 <= cc < cols and not np.isnan(data[rr, cc])\n",
    "                                                   for rr, cc in neighbors):\n",
    "                                                # Mark all eight pixels around the NaN\n",
    "                                                for rr, cc in neighbors:\n",
    "                                                    dead_pixels.add((rr, cc))\n",
    "                                            # Stop further checks once flagged\n",
    "                                            break\n",
    "                                else:\n",
    "                                    continue\n",
    "                                break\n",
    "                        else:\n",
    "                            continue\n",
    "                        break\n",
    "\n",
    "            else:\n",
    "                # Only consider “inner” pixels (not on borders)\n",
    "                if 0 < row < rows-1 and 0 < column < cols-1:\n",
    "                    jump_count = 0\n",
    "                    for dr in [-1, 0, 1]:\n",
    "                        for dc in [-1, 0, 1]:\n",
    "                            if dr == 0 and dc == 0:\n",
    "                                continue\n",
    "                            r, c = row + dr, column + dc\n",
    "                            if absolute_change(data[row, column], data[r, c]) > threshold:\n",
    "                                jump_count += 1\n",
    "                    if jump_count >= 2:\n",
    "                        closed_shape_pixels.add((row, column))\n",
    "\n",
    "    mask = find_closed_shape_contour(data, closed_shape_pixels)\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if mask[i, j] or np.isnan(data[i, j]):\n",
    "                dead_pixels.add((i, j))\n",
    "            else:\n",
    "                # x-axis checks\n",
    "                if (j == 0 and absolute_change(data[i, j], data[i, j + 1]) > threshold) or \\\n",
    "                   (j == cols - 1 and absolute_change(data[i, j], data[i, j - 1]) > threshold) or \\\n",
    "                   (0 < j < cols - 1 and absolute_change(data[i, j], data[i, j - 1]) > threshold and \\\n",
    "                    absolute_change(data[i, j], data[i, j + 1]) > threshold):\n",
    "                    dead_pixels.add((i, j))\n",
    "                # y-axis checks\n",
    "                if (i == 0 and absolute_change(data[i, j], data[i + 1, j]) > threshold) or \\\n",
    "                   (i == rows - 1 and absolute_change(data[i, j], data[i - 1, j]) > threshold) or \\\n",
    "                   (0 < i < rows - 1 and absolute_change(data[i, j], data[i - 1, j]) > threshold and \\\n",
    "                    absolute_change(data[i, j], data[i + 1, j]) > threshold):\n",
    "                    dead_pixels.add((i, j))\n",
    "\n",
    "    return [list(pixel) for pixel in set(dead_pixels)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71d3c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import label\n",
    "\n",
    "def classify_dead_pixels(pixels):\n",
    "    # Create a binary mask for the dead pixels\n",
    "    mask = np.zeros((max(p[0] for p in pixels) + 1, max(p[1] for p in pixels) + 1), dtype=int)\n",
    "    for p in pixels:\n",
    "        mask[p[0], p[1]] = 1\n",
    "\n",
    "    # Label connected components\n",
    "    labeled_array, num_features = label(mask)\n",
    "\n",
    "    # Group pixels by connected components\n",
    "    groups = {}\n",
    "    for p in pixels:\n",
    "        group_id = labeled_array[p[0], p[1]]\n",
    "        if group_id not in groups:\n",
    "            groups[group_id] = []\n",
    "        groups[group_id].append(p)\n",
    "\n",
    "    # Sort groups by size in descending order\n",
    "    sorted_groups = sorted(groups.values(), key=len, reverse=True)\n",
    "\n",
    "    return sorted_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25035426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pixels(file, threshold=1.3, slices=1, min_slices=1, debug_length=10):\n",
    "    \"\"\"\n",
    "    Filters pixels based on their presence in previous and next slices.\n",
    "\n",
    "    Parameters:\n",
    "        file (str): Path to the FITS file.\n",
    "        threshold (float): Threshold for identifying dead pixels.\n",
    "        slices (int): Number of slices to check before and after the current slice.\n",
    "        min_slices (int): Minimum number of slices (previous + next) where the pixel must appear.\n",
    "\n",
    "    Returns:\n",
    "        list: All clusters of dead pixels.\n",
    "    \"\"\"\n",
    "    all_pixels = []\n",
    "\n",
    "    with fits.open(file) as hdul:\n",
    "        data = hdul[1].data\n",
    "        for i in range(data.shape[0])[:debug_length]:\n",
    "            dead_pixels = find_dead_pixels(data[i, :, :], threshold)\n",
    "            clusters = classify_dead_pixels(dead_pixels)\n",
    "            all_pixels.append(clusters)\n",
    "\n",
    "    flattened_pixels = [[coord for group in clusters for coord in group] for clusters in all_pixels]\n",
    "\n",
    "    new_pixels = []\n",
    "\n",
    "    for i, array in enumerate(flattened_pixels):\n",
    "        pixel_groups = []\n",
    "        for pixel in array:\n",
    "            count_in_prev = sum(pixel in flattened_pixels[i - j] for j in range(1, slices + 1) if i - j >= 0)\n",
    "            count_in_next = sum(pixel in flattened_pixels[i + j] for j in range(1, slices + 1) if i + j < len(flattened_pixels))\n",
    "            if count_in_prev + count_in_next >= min_slices:\n",
    "                pixel_groups.append(pixel)\n",
    "        new_pixels.append(pixel_groups)\n",
    "\n",
    "    return new_pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0b79392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_segments(points):\n",
    "    \"\"\"\n",
    "    Splits a sorted list of points into continuous segments.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    points : list of int\n",
    "        A sorted list of integer points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of list of int\n",
    "        A list of continuous segments, where each segment is a list of integers.\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    current_segment = [points[0]]\n",
    "    for i in range(1, len(points)):\n",
    "        if points[i] == points[i - 1] + 1:\n",
    "            current_segment.append(points[i])\n",
    "        else:\n",
    "            segments.append(current_segment)\n",
    "            current_segment = [points[i]]\n",
    "    segments.append(current_segment)\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d92b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def interpolate_dead_pixels(data, dead_pixel_data, confidence_treshold=4, max_radius=1, iterations=1):\n",
    "    interpolated = data.copy().astype(float)\n",
    "    initial_dead_pixels = dead_pixel_data\n",
    "    #print(initial_dead_pixels)\n",
    "    for pixel in initial_dead_pixels:\n",
    "        interpolated[pixel[0], pixel[1]] = np.nan\n",
    "\n",
    "    low_confidence_pixels, high_confidence_pixels = [], []\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        # 1) Detect all dead pixels and normalize to tuple coords\n",
    "        dead_pixels = initial_dead_pixels\n",
    "        #print(dead_pixels)\n",
    "        dead_set = {tuple(dp) for dp in dead_pixels}\n",
    "        if not dead_set:\n",
    "            break\n",
    "\n",
    "        # 2) Cluster into connected components (8-connectivity)\n",
    "        def get_neighbors(pt):\n",
    "            r, c = pt\n",
    "            for dr in (-1, 0, 1):\n",
    "                for dc in (-1, 0, 1):\n",
    "                    if dr == 0 and dc == 0:\n",
    "                        continue\n",
    "                    nbr = (r + dr, c + dc)\n",
    "                    if nbr in dead_set:\n",
    "                        yield nbr\n",
    "\n",
    "        components = []\n",
    "        visited = set()\n",
    "        for pix in dead_set:\n",
    "            if pix in visited:\n",
    "                continue\n",
    "            queue = deque([pix])\n",
    "            comp = []\n",
    "            visited.add(pix)\n",
    "            while queue:\n",
    "                cur = queue.popleft()\n",
    "                comp.append(cur)\n",
    "                for nbr in get_neighbors(cur):\n",
    "                    if nbr not in visited:\n",
    "                        visited.add(nbr)\n",
    "                        queue.append(nbr)\n",
    "            components.append(comp)\n",
    "\n",
    "        # 3) Identify corner pixels for each component\n",
    "        corner_pixels = set()\n",
    "        for comp in components:\n",
    "            for r, c in comp:\n",
    "                non_dead_neighbors = 0\n",
    "                for dr in (-1, 0, 1):\n",
    "                    for dc in (-1, 0, 1):\n",
    "                        if dr == 0 and dc == 0:\n",
    "                            continue\n",
    "                        nr, nc = r + dr, c + dc\n",
    "                        if 0 <= nr < data.shape[0] and 0 <= nc < data.shape[1] and (nr, nc) not in dead_set:\n",
    "                            non_dead_neighbors += 1\n",
    "                if non_dead_neighbors >= 4:\n",
    "                    corner_pixels.add((r, c))\n",
    "        \n",
    "        # Remove low confidence pixels from corner pixels\n",
    "        corner_pixels.difference_update(low_confidence_pixels)\n",
    "        #print(corner_pixels)\n",
    "\n",
    "        pixels_dict = {}\n",
    "        # 4) For each corner pixel, compute neighbors and interpolate\n",
    "        for r, c in corner_pixels:\n",
    "            candidates = []\n",
    "            for dr in range(-max_radius, max_radius + 1):\n",
    "                for dc in range(-max_radius, max_radius + 1):\n",
    "                    nr, nc = r + dr, c + dc\n",
    "                    if (dr == 0 and dc == 0) or not (0 <= nr < interpolated.shape[0] and 0 <= nc < interpolated.shape[1]):\n",
    "                        continue\n",
    "                    val = interpolated[nr, nc]\n",
    "                    if not np.isnan(val):\n",
    "                        dist = np.hypot(dr, dc)\n",
    "                        candidates.append(((nr, nc), val, dist))\n",
    "            pixels_dict[(r, c)] = candidates\n",
    "\n",
    "            if not candidates:\n",
    "                continue\n",
    "\n",
    "        for pix, candidates in pixels_dict.items():\n",
    "            x_points = [neighbor_coordinates[1] for neighbor_coordinates, val, dist in candidates if neighbor_coordinates[0] == pix[0]]\n",
    "            x_points_vals = [val for neighbor_coordinates, val, dist in candidates if neighbor_coordinates[0] == pix[0]]\n",
    "\n",
    "            y_points = [neighbor_coordinates[0] for neighbor_coordinates, val, dist in candidates if neighbor_coordinates[1] == pix[1]]\n",
    "            y_points_vals = [val for neighbor_coordinates, val, dist in candidates if neighbor_coordinates[1] == pix[1]]\n",
    "\n",
    "            if not x_points or not y_points:\n",
    "                interpolated[pix[0], pix[1]] = np.nan\n",
    "                continue\n",
    "        \n",
    "            # split the x_points into n lists with the break at the point where the list is not continuous\n",
    "            x_segments = split_into_segments(x_points)\n",
    "            x_segments = [segment for segment in x_segments if any(abs(x - pix[1]) == 1 for x in segment)]\n",
    "            x_points_vals = [x_points_vals[x_points.index(x)] for segment in x_segments for x in segment]\n",
    "\n",
    "            y_segments = split_into_segments(y_points)\n",
    "            y_segments = [segment for segment in y_segments if any(abs(y - pix[0]) == 1 for y in segment)]\n",
    "            y_points_vals = [y_points_vals[y_points.index(y)] for segment in y_segments for y in segment]\n",
    "\n",
    "            x_points = [x for segment in x_segments for x in segment]\n",
    "            y_points = [y for segment in y_segments for y in segment]\n",
    "            \n",
    "            # linear fit\n",
    "            try:\n",
    "                popt_x, pcov_x = np.polyfit(x_points, x_points_vals, 1, cov=True)\n",
    "                popt_y, pcov_y = np.polyfit(y_points, y_points_vals, 1, cov=True)\n",
    "            except np.linalg.LinAlgError as e:\n",
    "                #print(f\"Error during linear fit for pixel {pix}: {e}\")\n",
    "                interpolated[pix[0], pix[1]] = np.nan\n",
    "                continue\n",
    "            except ValueError as e:\n",
    "                #print(f\"ValueError during linear fit for pixel {pix}: {e}\")\n",
    "                interpolated[pix[0], pix[1]] = np.nan\n",
    "                continue\n",
    "            except TypeError as e:\n",
    "                #print(f\"TypeError during linear fit for pixel {pix}: {e}\")\n",
    "                interpolated[pix[0], pix[1]] = np.nan\n",
    "                continue\n",
    "\n",
    "\n",
    "            # Find the point value\n",
    "            new_x = np.polyval(popt_x, pix[1])\n",
    "            new_y = np.polyval(popt_y, pix[0])\n",
    "\n",
    "            # Ensure correlation values are non-negative for weights\n",
    "            weight_x = abs(np.std([x - (popt_x[0] * x + popt_x[1]) for x in x_points_vals]))\n",
    "            weight_y = abs(np.std([y - (popt_y[0] * y + popt_y[1]) for y in y_points_vals]))\n",
    "\n",
    "            # Normalize weights\n",
    "            total_weight = 1 / weight_x + 1 / weight_y\n",
    "            weight_x = (1 / weight_x) / total_weight\n",
    "            weight_y = (1 / weight_y) / total_weight\n",
    "\n",
    "            # Weighted average\n",
    "            interpolated_value = weight_x * new_x + weight_y * new_y\n",
    "\n",
    "            # Calculate confidence as the inverse of the standard deviation of residuals\n",
    "            confidence_x = 1 / (np.std([x - (popt_x[0] * x + popt_x[1]) for x in x_points_vals]) + 1e-6)\n",
    "            confidence_y = 1 / (np.std([y - (popt_y[0] * y + popt_y[1]) for y in y_points_vals]) + 1e-6)\n",
    "            confidence = (confidence_x + confidence_y) / 2\n",
    "\n",
    "            # Print or store confidence for debugging or analysis\n",
    "            #print(f\"Pixel {pix}: Interpolated value = {interpolated_value}, Confidence = {confidence}\")\n",
    "            if confidence < confidence_treshold:\n",
    "                #print(f\"Confidence too low for pixel {pix}: {confidence}\")\n",
    "                low_confidence_pixels.append(pix)\n",
    "            else:\n",
    "                high_confidence_pixels.append([pix, confidence])\n",
    "\n",
    "            # Assign the interpolated value to the pixel\n",
    "            interpolated[pix[0], pix[1]] = interpolated_value\n",
    "            #remove [pix[0], pix[1]] from initial_dead_pixels\n",
    "            initial_dead_pixels.remove(list(pix))\n",
    "\n",
    "        #remove duplicates from low confidence pixels\n",
    "        low_confidence_pixels = list(set(low_confidence_pixels))\n",
    "#        for pixel in low_confidence_pixels:\n",
    "#            interpolated[pixel[0], pixel[1]] = np.nan\n",
    "\n",
    "    # turn it into a dictionary\n",
    "    high_confidence_pixels = {pixel[0]: pixel[1] for pixel in high_confidence_pixels}\n",
    "    #print(high_confidence_pixels)\n",
    "    #print(f\"Overall average confidence of {np.mean(high_confidence_pixels)}\")\n",
    "\n",
    "    return interpolated, high_confidence_pixels\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
